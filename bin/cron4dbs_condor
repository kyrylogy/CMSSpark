#!/bin/bash
# this script is designed to be used in crontab, i.e. with full path
# adjust script to put your desired notification address if necessary

#addr=cms-popdb-alarms@cern.ch
#addr=vkuznet@gmail.com
addr=cms-comp-monit-alerts@cern.ch

# DO NOT EDIT BELOW THIS LINE
# for Spark 2.X
export PATH=$PATH:/usr/hdp/hadoop/bin
export HADOOP_CONF_DIR=/etc/hadoop/conf

# find out which date we should use to run the script
year=`date +'%Y'`
month=`date +'%m'`
day=`date +'%d'`
hdir=hdfs:///project/monitoring/archive/condor/raw/metric
tmpDirs=`hadoop fs -ls ${hdir}/$year/$month | grep tmp$ | awk '{print $8}' | sed -e "s,\.tmp,,g" -e "s,${hdir},,g"`
pat=`echo $tmpDirs | tr ' ' '|'`
lastSnapshot=`hadoop fs -ls ${hdir}/$year/$month | egrep -v ${pat} | tail -1 | awk '{print $8}'`
#echo "Last available snapshot"
#echo $lastSnapshot
date=`echo $lastSnapshot | sed -e "s,${hdir},,g" -e "s,/,,g"`
odir=hdfs:///cms/dbs_condor

# set log area and environment
me=$(dirname "$0")
wdir=`echo $me | sed -e "s,/bin,,g"`
mkdir -p $wdir/logs
log=$wdir/logs/dbs_condor-`date +%Y%m%d`.log
export PYTHONPATH=$wdir/src/python:$PYTHONPATH
export PATH=$wdir/bin:$PATH

echo "Start job for $year/$month/$day ..." >> $log 2>&1
hadoop fs -ls ${hdir}/$year/$month >> $log 2>&1
echo "Date to run: $date" >> $log 2>&1

# check if we got a date to run
if [ -z "${date}" ]; then
    echo "No date to run" >> $log 2>&1
    exit
fi
dotmp=`echo $date | grep tmp`
if [ -n "${dotmp}" ]; then
    echo "Date ends with tmp" >> $log 2>&1
    exit
fi

# create appropriate area in our output directory, do not include day dir since it will be create by a job
hadoop fs -mkdir -p ${odir}/campaign/${year}/${month}
hadoop fs -mkdir -p ${odir}/dataset/${year}/${month}
hadoop fs -mkdir -p ${odir}/release/${year}/${month}
hadoop fs -mkdir -p ${odir}/era/${year}/${month}

# check that we need to run
oday=`echo $date | cut -c 7-8`
check=`hadoop fs -ls ${odir}/dataset/${year}/${month}/${oday} 2> /dev/null`
if [ -n "${check}" ]; then
    echo "No dir to run" >> $log 2>&1
    exit
fi

# setup to run the script
cmd="$wdir/bin/run_spark dbs_condor.py --yarn --fout=$odir --date=$date"
#echo "Will execute ..."
#echo $cmd
msg="Error while executing $cmd on $USER@`hostname` log at $log"
set -e
#trap "echo \"$msg\" | mail -s \"Cron alert run_spark dbs_condor\" \"$addr\"" ERR
# Call func function on exit
trap func exit
# Declare the function
function func() {
    local status=$?
    if [ $status -ne 0 ]; then
        local msg="cron4dbs_condor completed with non zero status"
        if [ -f /data/cms/bin/amtool ]; then
            local expire=`date -d '+1 hour' --rfc-3339=ns | tr ' ' 'T'`
            local urls="http://cms-monitoring.cern.ch:30093 http://cms-monitoring-ha1.cern.ch:30093 http://cms-monitoring-ha2.cern.ch:30093"
            for url in $urls; do
                /data/cms/bin/amtool alert add cron4dbs_condor \
                    alertname=cron4dbs_condor severity=medium tag=cronjob alert=amtool \
                    --end=$expire \
                    --annotation=summary="$msg" \
                    --annotation=date="`date`" \
                    --annotation=hostname="`hostname`" \
                    --annotation=status="$status" \
                    --annotation=command="$cmd" \
                    --annotation=log="$log" \
                    --alertmanager.url=$url
            done
        else
            echo "$msg" | mail -s "Cron alert cron4dbs_condor" "$addr"
        fi
    fi
}

$cmd >> $log 2>&1

# ----- CRON SUCCESS CHECK -----
# This cron job modifies yesterdays data every day, and treshold should be 12 hours - 43200
TIME_TRESHOLD=43200
# 0 */3 * * * /data/cms/CMSSpark/bin/cron4dbs_condor
# Size tresholds
campaign=200000000 # (20MB)
dataset=200000000 # (20MB)
era=100000 # (100KB)
release=100000 # (100KB)

# BUG: file is not generated on the last day of the month
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
DATE_HDFS=$(date -d "yesterday" '+%Y/%m/%d')
# Check all 4 directories with yesterdays date modified during last 12 hours with corresponding size tresholds
# exits 210 if one of the checks fails
trap 'EC'=210 ERR
/bin/bash  "$SCRIPT_DIR"/utils/check_utils.sh check_hdfs "$odir"/campaign/"$DATE_HDFS" "$TIME_TRESHOLD" $campaign || EC=$?
/bin/bash  "$SCRIPT_DIR"/utils/check_utils.sh check_hdfs "$odir"/dataset/"$DATE_HDFS" "$TIME_TRESHOLD" $dataset || EC=$? 
/bin/bash  "$SCRIPT_DIR"/utils/check_utils.sh check_hdfs "$odir"/era/"$DATE_HDFS" "$TIME_TRESHOLD" $era || EC=$?
/bin/bash  "$SCRIPT_DIR"/utils/check_utils.sh check_hdfs "$odir"/release/"$DATE_HDFS" "$TIME_TRESHOLD" $release || EC=$?
exit $EC
# RUNNING COMMANDS AFTER THIS POINT WILL CHANGE EXIT CODE
